{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67b1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql\n",
    "from pyspark.sql.functions import *\n",
    "sc = pyspark.SparkContext(appName=\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fce444",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)\n",
    "bank = spark.read.csv(path='bank.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b8eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "df = bank.select('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit')\n",
    "cols = df.columns\n",
    "\n",
    "categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a5f82",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2dda99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a338a60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786206847886866"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "predictions_lr = lrModel.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75cf10",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c4e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "dtModel = dt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ccb6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6852198334335932"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dt = dtModel.transform(test)\n",
    "evaluator.evaluate(predictions_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e2c5bb",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25e7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4365af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747424853711946"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rf = rfModel.transform(test)\n",
    "evaluator.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824987de",
   "metadata": {},
   "source": [
    "### Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287bb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import FMClassifier\n",
    "fm=FMClassifier( featuresCol='features',labelCol='label')\n",
    "fmModel = fm.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a0251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6890260575343868"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_fm = fmModel.transform(test)\n",
    "evaluator.evaluate(predictions_fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bde078",
   "metadata": {},
   "source": [
    "### Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da28ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt=GBTClassifier( featuresCol='features',labelCol='label')\n",
    "gbtModel = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ccfeb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882896865369111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_gbt = gbtModel.transform(test)\n",
    "evaluator.evaluate(predictions_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6a89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
